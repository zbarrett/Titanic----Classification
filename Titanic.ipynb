{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500   NaN        S\n",
       "1         1       1  female  38.0      1      0  71.2833   C85        C\n",
       "2         1       3  female  26.0      0      0   7.9250   NaN        S\n",
       "3         1       1  female  35.0      1      0  53.1000  C123        S\n",
       "4         0       3    male  35.0      0      0   8.0500   NaN        S"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "dataset = dataset.drop(columns=['Name', 'PassengerId', 'Ticket'])\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for row in dataset.iloc[:,7]:\n",
    "    row = str(row)    \n",
    "    if row == 'nan' or row[0] == 'n':\n",
    "        cabins = 0\n",
    "    else:\n",
    "        cabins = row.count(' ') + 1\n",
    "    dataset.iat[i, 7] = cabins\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0\n",
    "S = 0\n",
    "Q = 0\n",
    "for row in dataset.iloc[:, 8]:\n",
    "    row = str(row)\n",
    "    if row == 'C':\n",
    "        C += 1\n",
    "    elif row  == 'S':\n",
    "        S += 1\n",
    "    elif row == 'Q':\n",
    "        Q += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for row in dataset.iloc[:,8]:\n",
    "    row = str(row)\n",
    "    if row == 'nan':\n",
    "        dataset.iat[i, 8] = 'S' # S is most frequent\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_dict = {\"Embarked\": {\"S\": 0, \"C\": 1, \"Q\": 2}}\n",
    "dataset.replace(embarked_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TotFamSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin  Embarked  \\\n",
       "0         0       3    male  22.0      1      0   7.2500     0         0   \n",
       "1         1       1  female  38.0      1      0  71.2833     1         1   \n",
       "2         1       3  female  26.0      0      0   7.9250     0         0   \n",
       "3         1       1  female  35.0      1      0  53.1000     1         0   \n",
       "4         0       3    male  35.0      0      0   8.0500     0         0   \n",
       "\n",
       "   TotFamSize  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['TotFamSize'] = dataset['Parch'] + dataset['SibSp']\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(891,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values\n",
    "\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zach Barrett\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'median', axis = 0)\n",
    "imputer = imputer.fit(X[:, 2:3])\n",
    "X[:, 2:3] = imputer.transform(X[:, 2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X.fit_transform(X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zach Barrett\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Zach Barrett\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [7])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 10)\n"
     ]
    }
   ],
   "source": [
    "# Dummy variable trap\n",
    "X = np.delete(X, obj = 0, axis = 1)\n",
    "\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "classifier = xgb.XGBClassifier()\n",
    "# classifier = RandomForestClassifier(n_estimators = 20, max_depth = 10, criterion = 'entropy', bootstrap = False)\n",
    "# classifier = SVC(kernel = 'rbf', gamma = 0.01, C = 100)\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,  17],\n",
       "       [ 24,  63]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8294436906377205"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04184580057687378"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'max_depth': [5, 10, 25, 50, None], 'n_estimators': [15, 20, 25, 30], 'bootstrap': [True, False]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = 'accuracy',\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rms = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print (\"RMS error:\" rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_submission = pd.read_csv('test.csv')\n",
    "dataset_submission = dataset_submission.drop(columns=['Name', 'Ticket'])\n",
    "\n",
    "dataset_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for row in dataset_submission.iloc[:,7]:\n",
    "    row = str(row)\n",
    "    if row == 'nan':\n",
    "        cabins = 0\n",
    "    else:\n",
    "        cabins = row.count(' ') + 1\n",
    "    dataset_submission.iat[i, 7] = cabins\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0\n",
    "S = 0\n",
    "Q = 0\n",
    "for row in dataset_submission.iloc[:, 8]:\n",
    "    row = str(row)\n",
    "    if row == 'C':\n",
    "        C += 1\n",
    "    elif row  == 'S':\n",
    "        S += 1\n",
    "    elif row == 'Q':\n",
    "        Q += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for row in dataset_submission.iloc[:,8]:\n",
    "    row = str(row)\n",
    "    if row == 'nan':\n",
    "        dataset_subission.iat[i, 8] = 'S' # S is most frequent\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_dict = {\"Embarked\": {\"S\": 0, \"C\": 1, \"Q\": 2}}\n",
    "dataset_submission.replace(embarked_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TotFamSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass     Sex   Age  SibSp  Parch     Fare Cabin  Embarked  \\\n",
       "0          892       3    male  34.5      0      0   7.8292     0         2   \n",
       "1          893       3  female  47.0      1      0   7.0000     0         0   \n",
       "2          894       2    male  62.0      0      0   9.6875     0         2   \n",
       "3          895       3    male  27.0      0      0   8.6625     0         0   \n",
       "4          896       3  female  22.0      1      1  12.2875     0         0   \n",
       "\n",
       "   TotFamSize  \n",
       "0           0  \n",
       "1           1  \n",
       "2           0  \n",
       "3           0  \n",
       "4           2  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_submission['TotFamSize'] = dataset_submission['Parch'] + dataset_submission['SibSp']\n",
    "\n",
    "dataset_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission = dataset_submission.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zach Barrett\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'median', axis = 0)\n",
    "\n",
    "imputer = imputer.fit(X_submission[:, 2:3])\n",
    "X_submission[:, 2:3] = imputer.transform(X_submission[:, 2:3]) # needs to be vector but just does 2\n",
    "imputer = imputer.fit(X_submission[:, 5:6])\n",
    "X_submission[:, 5:6] = imputer.transform(X_submission[:, 5:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X_submission[:, 1] = labelencoder_X.fit_transform(X_submission[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 9)\n",
      "[3 3 2 3 3 3 3 2 3 3 3 1 1 2 1 2 2 3 3 3 1 3 1 1 1 3 1 3 1 3 2 2 3 3 1 3 3\n",
      " 3 3 3 3 1 3 2 1 3 1 3 1 3 1 2 2 1 2 3 3 3 3 1 3 2 3 3 1 2 3 1 1 1 3 3 3 1\n",
      " 1 1 3 1 2 3 3 1 1 3 2 3 3 3 3 2 3 3 1 3 1 3 1 3 3 3 1 2 3 3 3 3 3 3 3 2 2\n",
      " 3 1 3 1 3 3 3 1 2 2 3 1 3 3 3 3 3 2 3 3 1 3 3 3 3 3 2 3 3 3 1 1 2 1 3 1 3\n",
      " 1 2 1 3 3 3 3 3 1 3 1 3 3 3 2 3 2 3 1 3 1 3 3 3 3 3 3 2 2 1 2 1 2 1 1 3 1\n",
      " 2 2 3 3 2 2 1 3 2 2 3 1 3 2 3 3 3 1 2 2 1 3 2 1 3 3 3 2 2 3 1 3 1 1 3 2 3\n",
      " 2 3 1 3 3 3 3 2 2 1 3 3 1 3 1 3 2 1 1 2 1 3 3 1 2 2 2 3 2 3 1 3 3 3 3 3 2\n",
      " 3 3 3 2 3 2 3 1 3 3 3 1 3 1 3 3 2 2 2 2 2 3 3 3 3 3 3 3 1 3 3 1 3 3 1 3 3\n",
      " 2 3 1 3 3 2 2 3 3 1 1 3 1 3 3 3 3 3 1 3 1 2 3 2 3 3 2 1 1 3 2 1 2 2 2 1 3\n",
      " 3 3 1 2 3 2 3 2 3 3 1 3 3 2 3 2 2 1 2 2 2 3 1 1 3 3 3 3 2 2 3 1 3 3 3 1 2\n",
      " 2 1 1 2 1 1 3 2 1 3 3 3 3 3 2 2 3 2 3 3 1 1 3 2 3 1 3 1 3 3 1 2 1 1 1 2 2\n",
      " 1 3 3 3 1 3 3 1 3 3 3]\n",
      "[1 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0\n",
      " 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1\n",
      " 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1\n",
      " 1 1 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0\n",
      " 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 0\n",
      " 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1\n",
      " 1 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1\n",
      " 1 0 0 0 0 0 1 0 1 1 1]\n",
      "[34.5 47.0 62.0 27.0 22.0 14.0 30.0 26.0 18.0 21.0 27.0 46.0 23.0 63.0\n",
      " 47.0 24.0 35.0 21.0 27.0 45.0 55.0 9.0 27.0 21.0 48.0 50.0 22.0 22.5 41.0\n",
      " 27.0 50.0 24.0 33.0 27.0 30.0 18.5 27.0 21.0 25.0 27.0 39.0 27.0 41.0\n",
      " 30.0 45.0 25.0 45.0 27.0 60.0 36.0 24.0 27.0 20.0 28.0 27.0 10.0 35.0\n",
      " 25.0 27.0 36.0 17.0 32.0 18.0 22.0 13.0 27.0 18.0 47.0 31.0 60.0 24.0\n",
      " 21.0 29.0 28.5 35.0 32.5 27.0 55.0 30.0 24.0 6.0 67.0 49.0 27.0 27.0 27.0\n",
      " 27.0 18.0 27.0 2.0 22.0 27.0 27.0 27.0 25.0 25.0 76.0 29.0 20.0 33.0 43.0\n",
      " 27.0 27.0 26.0 16.0 28.0 21.0 27.0 27.0 18.5 41.0 27.0 36.0 18.5 63.0\n",
      " 18.0 27.0 1.0 36.0 29.0 12.0 27.0 35.0 28.0 27.0 17.0 22.0 27.0 42.0 24.0\n",
      " 32.0 53.0 27.0 27.0 43.0 24.0 26.5 26.0 23.0 40.0 10.0 33.0 61.0 28.0\n",
      " 42.0 31.0 27.0 22.0 27.0 30.0 23.0 27.0 60.5 36.0 13.0 24.0 29.0 23.0\n",
      " 42.0 26.0 27.0 7.0 26.0 27.0 41.0 26.0 48.0 18.0 27.0 22.0 27.0 27.0 23.0\n",
      " 27.0 40.0 15.0 20.0 54.0 36.0 64.0 30.0 37.0 18.0 27.0 27.0 40.0 21.0\n",
      " 17.0 27.0 40.0 34.0 27.0 11.5 61.0 8.0 33.0 6.0 18.0 23.0 27.0 27.0 0.33\n",
      " 47.0 8.0 25.0 27.0 35.0 24.0 33.0 25.0 32.0 27.0 17.0 60.0 38.0 42.0 27.0\n",
      " 57.0 50.0 27.0 30.0 21.0 22.0 21.0 53.0 27.0 23.0 27.0 40.5 36.0 14.0\n",
      " 21.0 21.0 27.0 39.0 20.0 64.0 20.0 18.0 48.0 55.0 45.0 45.0 27.0 27.0\n",
      " 41.0 22.0 42.0 29.0 27.0 0.92 20.0 27.0 24.0 32.5 27.0 27.0 28.0 19.0\n",
      " 21.0 36.5 21.0 29.0 1.0 30.0 27.0 27.0 27.0 27.0 17.0 46.0 27.0 26.0 27.0\n",
      " 27.0 20.0 28.0 40.0 30.0 22.0 23.0 0.75 27.0 9.0 2.0 36.0 27.0 24.0 27.0\n",
      " 27.0 27.0 30.0 27.0 53.0 36.0 26.0 1.0 27.0 30.0 29.0 32.0 27.0 43.0 24.0\n",
      " 27.0 64.0 30.0 0.83 55.0 45.0 18.0 22.0 27.0 37.0 55.0 17.0 57.0 19.0\n",
      " 27.0 22.0 26.0 25.0 26.0 33.0 39.0 23.0 12.0 46.0 29.0 21.0 48.0 39.0\n",
      " 27.0 19.0 27.0 30.0 32.0 39.0 25.0 27.0 18.0 32.0 27.0 58.0 27.0 16.0\n",
      " 26.0 38.0 24.0 31.0 45.0 25.0 18.0 49.0 0.17 50.0 59.0 27.0 27.0 30.0\n",
      " 14.5 24.0 31.0 27.0 25.0 27.0 27.0 22.0 45.0 29.0 21.0 31.0 49.0 44.0\n",
      " 54.0 45.0 22.0 21.0 55.0 5.0 27.0 26.0 27.0 19.0 27.0 24.0 24.0 57.0 21.0\n",
      " 6.0 23.0 51.0 13.0 47.0 29.0 18.0 24.0 48.0 22.0 31.0 30.0 38.0 22.0 17.0\n",
      " 43.0 20.0 23.0 50.0 27.0 3.0 27.0 37.0 28.0 27.0 39.0 38.5 27.0 27.0]\n",
      "[0 1 0 0 1 0 0 1 0 2 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 0 2 1 2 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 2 3 0 4 0 0 1 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 2 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 1 5 0 1 0 0 3 0 0\n",
      " 0 1 0 0 0 0 4 0 0 0 0 0 0 1 0 0 0 1 0 2 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1\n",
      " 0 0 2 8 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 4 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 1 2 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 2 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 2 0 0 1 8 1 0 0 1 1 1 0 0 0\n",
      " 1 0 0 0 1 0 2 0 0 4 0 0 0 1 0 1 0 0 0 3 0 0 0 0 3 1 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 1 0 1 0 0 0 0 0 1]\n",
      "[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 3 0 1 0 0 0 0 0 2 2 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 1 2 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 4 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 4 0 0 0 0 0 0 6 2 0 3 0 0 0 0 0\n",
      " 0 1 1 0 0 2 2 0 0 0 0 2 0 1 0 0 0 1 0 2 0 0 0 0 0 0 5 2 0 0 3 2 0 1 0 0 1\n",
      " 0 1 0 2 0 0 0 1 0 2 0 2 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 2 0 0 1 1 0 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 1 0 2 0 0 1 0 0 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 2 0 0 0 0 0 1 0 0 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 0\n",
      " 1 0 0 0 2 0 0 0 0 9 1 1 0 0 0 0 0 1 0 0 2 2 0 0 0 0 0 2 1 0 0 0 9 0 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 2 0 0 0 1 0 1 2 0 1 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 1]\n",
      "[7.8292 7.0 9.6875 8.6625 12.2875 9.225 7.6292 29.0 7.2292 24.15 7.8958\n",
      " 26.0 82.2667 26.0 61.175 27.7208 12.35 7.225 7.925 7.225 59.4 3.1708\n",
      " 31.6833 61.3792 262.375 14.5 61.9792 7.225 30.5 21.6792 26.0 31.5 20.575\n",
      " 23.45 57.75 7.2292 8.05 8.6625 9.5 56.4958 13.4167 26.55 7.85 13.0\n",
      " 52.5542 7.925 29.7 7.75 76.2917 15.9 60.0 15.0333 23.0 263.0 15.5792\n",
      " 29.125 7.8958 7.65 16.1 262.375 7.8958 13.5 7.75 7.725 262.375 21.0\n",
      " 7.8792 42.4 28.5375 263.0 7.75 7.8958 7.925 27.7208 211.5 211.5 8.05 25.7\n",
      " 13.0 7.75 15.2458 221.7792 26.0 7.8958 10.7083 14.4542 7.8792 8.05 7.75\n",
      " 23.0 13.9 7.775 52.0 8.05 26.0 7.7958 78.85 7.925 7.8542 8.05 55.4417\n",
      " 26.0 7.75 7.775 8.5167 22.525 7.8208 7.75 8.7125 13.0 15.0458 7.7792\n",
      " 31.6792 7.2833 221.7792 14.4542 6.4375 16.7 75.2417 26.0 15.75 7.75 57.75\n",
      " 7.25 7.75 16.1 7.7958 23.25 13.0 8.05 8.05 28.5 25.4667 6.4375 7.8958\n",
      " 7.8542 7.225 13.0 8.05 46.9 46.9 151.55 262.375 26.0 26.55 18.0 51.8625\n",
      " 8.05 26.55 26.0 83.1583 7.8958 14.4542 12.1833 31.3875 7.55 221.7792\n",
      " 7.8542 26.55 13.775 7.7333 15.2458 13.5 7.0 13.0 22.025 50.4958 34.375\n",
      " 27.7208 8.9625 7.55 7.225 13.9 7.2292 31.3875 39.0 36.75 55.4417 39.0\n",
      " 83.1583 13.0 83.1583 53.1 7.75 247.5208 16.0 21.0 8.05 69.55 13.0 26.0\n",
      " 26.0 14.5 12.35 32.5 7.8542 134.5 7.775 10.5 8.1125 15.5 14.4 227.525\n",
      " 26.0 10.5 25.7417 7.75 10.5 27.7208 7.8958 22.525 7.05 73.5 26.0 7.775\n",
      " 42.5 7.8792 164.8667 211.5 8.05 13.8583 8.05 10.5 7.7958 27.4458 15.2458\n",
      " 7.7958 7.75 15.1 13.0 65.0 26.55 6.4958 7.8792 71.2833 7.8542 75.25 7.225\n",
      " 13.0 106.425 27.7208 30.0 134.5 7.8875 23.45 51.8625 21.0 32.5 26.0\n",
      " 14.4542 27.75 7.925 136.7792 9.325 9.5 7.55 7.75 8.05 13.0 7.775 17.4\n",
      " 7.8542 23.0 12.1833 12.7375 7.8958 0.0 7.55 8.05 8.6625 75.2417 7.75\n",
      " 136.7792 15.5 7.225 26.0 10.5 26.0 21.0 10.5 8.6625 13.775 7.75 15.2458\n",
      " 20.2125 7.25 7.25 82.2667 7.2292 8.05 39.6 6.95 7.2292 81.8583 9.5 7.8958\n",
      " 41.5792 21.6792 45.5 7.8542 7.775 15.0458 21.0 8.6625 7.75 26.55 151.55\n",
      " 9.35 93.5 14.1083 8.6625 7.225 7.575 7.75 135.6333 7.7333 146.5208 10.5\n",
      " 7.8542 31.5 7.775 7.2292 13.0 26.55 211.3375 7.05 39.0 79.2 26.0 13.0\n",
      " 36.75 29.7 7.225 15.7417 7.8958 26.0 13.0 7.2292 31.5 7.2292 10.5 7.5792\n",
      " 69.55 512.3292 14.5 7.65 13.0 7.2292 13.5 21.0 63.3583 10.5 73.5 65.0\n",
      " 20.575 26.0 51.4792 7.8792 7.75 15.55 69.55 37.0042 21.0 8.6625 55.4417\n",
      " 69.55 14.4583 39.6875 59.4 13.8583 11.5 134.5 0.0 13.0 81.8583 262.375\n",
      " 8.6625 11.5 50.0 31.3875 7.75 7.8792 14.5 16.1 12.875 65.0 7.775 13.0\n",
      " 7.75 21.075 93.5 39.4 20.25 10.5 22.025 60.0 7.25 79.2 7.775 7.7333\n",
      " 164.8667 21.0 59.4 47.1 27.7208 13.8625 10.5 211.5 7.7208 13.775 7.75\n",
      " 90.0 7.775 8.05 108.9 7.25 8.05 22.3583]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 4 0 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 3 0 0 0 2 0 1 0 0 0 0 4 0 0 0 1 3 0 0 0 1\n",
      " 1 1 0 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 2 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 4 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 2 0 1 0 0 0 0 0 1 0 1 0 0 0 0 2 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 3 0 0 0 0 0 0 2 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 2 3 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0]\n",
      "[2 0 2 0 0 0 2 0 1 0 0 0 0 0 0 1 2 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 1 2 1 0 0 1 0 0 1 2 0 0 0 1 0 0 0 2 1 0 2 0 1 0 2 0 0 1\n",
      " 1 1 0 0 0 2 1 0 0 0 2 1 2 0 2 0 0 0 0 0 1 0 0 0 0 0 1 0 2 0 1 0 2 2 0 0 1\n",
      " 2 1 2 0 1 1 0 1 0 0 2 1 0 2 0 0 2 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 2 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 2 1\n",
      " 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 2 0 1 0 0 1 2 0 1 0 0 0 0 0 0 0 2 0 1 0 1 0\n",
      " 0 0 1 1 0 2 0 0 0 0 0 2 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 2 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 2 1 2 1 0 0 0 0 0 0 0 2 1 0 0 0 0 1 0 0 2 1 0 0 0\n",
      " 1 1 0 0 0 1 0 0 2 0 0 0 0 0 0 1 0 2 1 2 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 2 0 0 1 0 0 1 0 1 0 1 1\n",
      " 0 1 0 0 0 1 0 0 0 0 2 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 1 0 2 0 0 1 0 1 1 0\n",
      " 1 2 0 2 2 0 0 1 0 0 1]\n",
      "[0 1 0 0 2 0 0 2 0 2 0 0 1 1 1 1 0 0 1 0 1 1 0 1 4 1 1 0 0 2 1 2 3 3 1 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 2 1 0 3 5 0 5 0 0 1 0 0 0 0 0 4 0 0 0 0 5 0 0 0 0\n",
      " 0 0 0 2 0 0 2 1 0 0 0 1 0 0 0 2 1 0 3 0 0 0 1 0 0 0 1 1 0 0 2 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 2 0 1 0 1 1 0 0 1 0 2 0 0 0 0 4 1 0 0 0 0 0 7 7 0 4 0 0 3 0 0\n",
      " 0 2 1 0 0 2 6 0 0 0 0 2 0 2 0 0 0 2 0 4 0 0 0 0 1 0 6 2 0 1 3 2 0 2 1 0 2\n",
      " 0 1 2 10 0 1 0 2 0 2 0 2 0 0 0 0 2 1 2 0 0 0 0 0 0 0 0 0 1 6 0 0 2 2 0 1\n",
      " 0 0 0 0 2 0 0 0 0 0 0 1 0 1 0 1 0 2 1 0 2 2 0 3 1 0 2 1 1 3 0 1 0 0 0 0 0\n",
      " 0 0 1 0 2 2 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 2 0 2 2 0 0 1 0 0 0 0 0 2 0\n",
      " 0 3 2 0 0 0 0 1 0 0 2 3 1 2 1 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 3 0 1 0 2 0\n",
      " 0 2 0 0 0 2 0 0 0 0 10 1 2 0 0 0 0 0 1 0 0 3 3 0 2 0 0 1 10 2 0 0 1 10 1\n",
      " 0 1 0 1 0 0 0 2 0 2 0 0 6 0 0 0 1 0 3 0 0 0 4 0 1 2 0 4 1 0 2 0 0 0 1 1 0\n",
      " 1 0 1 2 0 2 0 1 0 0 0 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "print (X_submission.shape)\n",
    "\n",
    "for i in range(X_submission.shape[1]):\n",
    "    print (X_submission[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zach Barrett\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Zach Barrett\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [7])\n",
    "X_submission = onehotencoder.fit_transform(X_submission).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "print (X_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.]\n",
      "(418, 10)\n"
     ]
    }
   ],
   "source": [
    "# Dummy variable trap\n",
    "print (X_submission[:, 0])\n",
    "X_submission = np.delete(X_submission, obj = 0, axis = 1)\n",
    "\n",
    "print (X_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_submission = sc.fit_transform(X_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"PassengerId\": dataset_submission[\"PassengerId\"], \"Survived\": prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Predictions-XG.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
